<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Bayesian Inference</title>

    <link rel="stylesheet" href="../reveal.js/css/reveal.css">
    <link rel="stylesheet" href="workshop_theme.css">
    <!--link rel="stylesheet" href="../../../talks/web_based/WinterBootcamp/wb_theme.css"-->

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="../reveal.js/lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section class="titlepage">
          <div class="meeting">
            mEpiLab BEAST Workshop, September 5th 2016
          </div>
               
          <div class="title">
            <h1>Bayesian Inference</h1>
          </div>

          <div class="authors">
            Tim Vaughan
          </div>

          <div class="institution">
            Centre for Computational Evolution<br>
            The University of Auckland
          </div>

        </section>

        <section>
          <section class="center">
            <h2>Probability</h2>
          </section>

          <section>
            <h3>Logical reasoning</h3>

            Deductive reasoning can be reduced to the repeated application of the following syllogisms:

            <blockquote style="text-align:center">
              if $A$ is true, then $B$ is true<br>
              $A$ is true
              <hr>
              $B$ is true
            </blockquote>

            <blockquote style="text-align:center">
              if $A$ is true, then $B$ is true<br>
              $B$ is false
              <hr>
              $A$ is false
            </blockquote>

          </section>

          <section>
            <h3>A hole in logic</h3>

            <blockquote style="text-align:justify">Suppose some dark night a policeman walks down a street. He
              hears a burglar alarm, looks across the street, and sees a jewelry store with
              a broken window. Then a gentleman wearing a mask comes crawling out of the
              window, carrying a bag full of jewelry. The policeman decides immediately that
              the gentleman is a thief. How does he decide this?</blockquote>
            <div class="cite">Jaynes: Probability Theory</div>
          </section>

          <section>
            <h3>A hole in logic?</h3>

            <ul>
              <li>$A$: "the gentleman is a thief"</li>
              <li>$B$: "the gentleman is wearing a mask and exited a broken window holding a bag of jewelry".</li>
            </ul>

            <br>

            <p>The policeman seems to be applying the following weak syllogism:</p>
            <blockquote style="text-align:center">
              if $A$ is true, then $B$ is likely<br>
              $B$ is true
              <hr>
              $A$ is likely
            </blockquote>

            <div style="text-align:center"><i>Why does his reasoning seem so sound?</i></div>

          </section>

          <section>
            <h3>Developing a theory of<br>plausible reasoning</h3>

            Our theory must satisfy the following requirements:
            <ol>
              <li>Degrees of plausibility are represented by<br>real numbers.</li>
              <li>Require qualitative correspondence with<br>common sense.</li>
              <li>Consistency:
                <ol>
                  <li>All valid reasoning routes give the same result.</li>
                  <li>Equivalent states of knowledge must have equivalent degrees of plausibility.</li>
                </ol>
              </li>
            </ol>
          </section>

          <section>
            <h3>Probability: extended logic</h3>

            <p>These requirements are enough to uniquely identify the
            essential rules of probability theory!</p>

            <blockquote style="width:100%">
              <ul>
                <li>The probability $P(A|B)$ is the degree of
                plausibility of proposition $A$ given that $B$ is
                true.</li>
                <li>Product rule: $P(A|BC)P(B|C) = P(AB|C)$</li>
                <li>Sum rule: $P(A|B)+P(\bar{A}|B) = 1$</li>
              </ul>
            </blockquote>

            <p>By convention, $P(A)=0$ indicates $A$ is certainly
            false while $P(A)=1$ means $A$ is certainly true.</p>

            <div style="text-align:center;color:purple">That's it! You can now do Bayesian statistics!</div>
          </section>

          <section>
            <h3>A word about notation</h3>

            Strictly speaking, probabilities only ever concern propositions (i.e. things with true or false values):
            <blockquote style="text-align:center">
              <ul>
                <li>Tim is a Cat</li>
                <li>$N=5$</li>
              </ul>
            </blockquote>

            <p>A statement such as $P(N)$ is therefore as meaningless as $P(\text{Tim})$.</p>

            <p>However, where propositions concern the value of a variable like $N$, we often use $P(n)$
              as shorthand for $P(N=n)$.</p>

            <p>Abusing notation, this is sometimes written as $P(N)$.</p>
          </section>

          <section>
            <h3>Frequentist definition of probability</h3>

            <p>Traditionally, probability has been defined in terms of
            relative frequencies of outcomes of repeated random
            (weakly controlled) "experiments".</p>

            <img style="float:right; width:200px" data-src="dice_freq.svg">

            <div style="float:left;">
              <ul>
                <li>$N$: Total number of rolls.</li>
                <li>$n_5$: Total number of 5s rolled.</li>
                <li>$P(d=5) \equiv n_5/N$ as $N\rightarrow\infty$</li>
              </ul>
            </div>

            <blockquote style="clear:both;width:100%">
              There are several problems here:
            <ol>
              <li>Experiments are assumed to be repeatable.</li>
              <li>Assumes that randomness is a property of the system.</li>
              <li>Completely ignores $\sim 400$ years of physics.</li>
            </ol>

          </section>

          <section>
            <h3>Back to the Bayesian interpretation</h3>

            <p>The Bayesian interpretation treats probability as a
            measure of the plausibility of propositions <b>conditional on
            available information</b>.</p>

            <p>A single proposition can therefore have multiple
            probabilities depending on the available information!</p>
            <img style="width:100%" data-src="dice_inference.svg">
          </section>

          <section>
            <h3>Continuous hypothesis spaces</h3>

            Propositions regarding continuous variables require special treatment.
            <ul>
              <li>Suppose $X$ may take any value between 0 and 10.</li>
              <li>The probability $P(X=x)$ will always be zero!</li>
              <li>Instead, define $P(x&lt;X&lt;x+\delta) = \delta f(x)$</li>
            </ul>

            <blockquote>
              <ul>
                <li>$f(x)$ is a probability <i>density</i>.</li>
                <li>It is normalized: $\int_0^{10}f(x)dx=1$</li>
                <li>It is positive: $f(x)\geq 0$</li>
                <li>At a given point $f(x)$ may be $>1$!</li>
              </ul>
            </blockquote>
            Often, $f(x)$ follows the standard rules of probability.

          </section>
        </section>

        <section>
          <section class="center">
            <h2>Inference</h2>
          </section>

          <section>
            <h3>What is inference?</h3>

              <img style="float:right" data-src="inference.jpg">

            <blockquote style="float:left">
              Inference is the act of deriving logical conclusions from premises assumed to be true.
            </blockquote>

            <p style="clear:both">
            Statistical inference generalises this to situations where
            the premises are not sufficient to draw conclusions
            without uncertainty.</p>

            <p style="text-align:center;color:red">What is "data"?</p>

          </section>

          <section>
            <h3>Urn example</h3>

            <img style="float:right" data-src="urn.svg">
            <div style="float:left;width:60%"> 
              <ul>
                <li>An urn contains 11 balls: $N_r$ red and $11-N_r$ blue.</li>
                <li>Suppose we remove a ball (no peeking), record its colour, then replace it.</li>
                <li>Suppose we repeat this 2 more times, obtaining the sequence R,B,R.</li>
              </ul>
            </div>

            <p style="clear:both">How many of the balls in the urn are red? In other words,
              what is $P(N_r|d_1=R,d_2=B,d_3=R)$?
            </p>
          </section>

          <section>
            <h3>Urn example (continued)</h3>
            <p>Given the description of the process, it is more tractable to consider
            $$P(d_1,d_2,d_3|N_r)=P(d_3|N_r,d_1,d_2)P(d_2|N_r,d_1)P(d_1|N_r)$$</p>

            <p>Knowing nothing about the internal arrangement of the balls in the urn, we must have $P(d_1|N_r)=N_r/11$.</p>

            <p>In general $P(d_2|N_r,d_1)$ depends on the result of the first draw!</p>

            <blockquote style="width:80%">Cheat by assuming urn is shaken between draws
            and we know nothing of physics, so that
            $P(d_2|N_r,d_1)=P(d_2|N_r)$.</blockquote>
          </section>

          <section>
            <h3>Urn example (continued)</h3>
            Now we can claim
            \begin{align}
            P(d_1=R,d_2=B,d_3=R|N_r)&=\frac{N_r}{11}\times\frac{(11-N_r)}{11}\times\frac{N_r}{11}\\
            &=N_r^2(11-N_r)/11^3
            \end{align}

            Applying the product rule a couple of times yields:

            \begin{align}
            P(N_r|R,B,R)P(R,B,R)&=P(R,B,R|N_r)P(N_r)\\
            P(N_r|R,B,R)& = \frac{1}{P(R,B,R)}P(R,B,R|N_r)P(N_r)
            \end{align}

            <p>The term $P(R,B,R)$ is a function only of the data:
            constant. The term $P(N_r)$ specifies the plausibility of
            each possible value of $N_r$ in the absence of the
            data.</p>
          </section>

          <section>
            <h3>Urn example (continued)</h3>

            <div style="text-align:center">
              <img data-src="urn_posterior.png" style="width:80%">
            </div>
          </section>

          <section>
            <h3>Bayes theorem</h3>

            In answering this question we have accidentally used Bayes theorem:
            <blockquote>
              $$\color{cyan}{P(\theta_M|D,M)} = \frac{\color{orange}{P(D|\theta_M,M)}\color{red}{P(\theta|M)}}{\color{green}{P(D|M)}}$$
            </blockquote>
            Here $\theta_M$ are parameters of some model $M$ and $D$ is data assumed to be generated by that model.

            <p>The components of the equation even have names:
              <ul>
                <li>The <span style="color:darkcyan">posterior</span> of $\theta$: $P(\theta|D)$,</li>
                <li>the <span style="color:orange">likelihood</span> of $\theta$: $P(D|\theta)$, and</li>
                <li>the <span style="color:red">prior</span> of $\theta$: $P(\theta)$</li>
              </ul>
            </p>
          </section>
        </section>

        <section>
          <section class="center">
            <h2>Prior Probabilities</h2>
          </section>

          <section>
            <h3>What is a prior probability?</h3>

            A prior probability is:
            <blockquote style="margin-top:50px"> A probability!</blockquote>

            <blockquote style="margin-top:50px;margin-bottom:50px">The probability of whatever you're interested in but
              in the absence of possibly relevant data.</blockquote>

            In principle, any two (rational) people with access to the same information should
            specify exactly the same prior.

            <p style="text-align:center;color:red">In practice this often isn't true.</p>
          </section>

          <section>
            <h3>Prior probabilities are necessary</h3>

            Isn't the need for priors a problem with the Bayesian approach?

            <div style="text-align:center"><p style="font-size:2em;font-weight:bold">NO!</p></div>

            <blockquote>
              <ul>
                <li>It is not possible to do inference without making assumptions.</li>
                <li>Priors allow previous knowledge to be incorporated.</li>
                <li>Frequentist (and Likelihoodist) methods also use priors: it's just not clear what they are!</li>
              </ul>

            </blockquote>
          </section>

          <section>
            <h3>Priors for discrete variables</h3>

            <img style="float:right;width:40%" data-src="poissonian.png">
            <div style="width:60%">
              <ul>
                <li> Defining priors for discrete variables with finite bounds
                  is often straight-forward.</li>
                <li>Principle of indifference.</li>
                <li>For discrete variables representing the number
                  of events that occur in a given interval, a Poissonian distribution may be
                  appropriate.</li>
              </ul>
            </div>
          </section>

          <section>
            <h3>Priors for continuous variables</h3>

            <p>For a continuous variable $a&lt;x&lt;b$, sensible priors may include</p>
            <ul>
              <li>The uniform distribution $f(x)=1/(b-a)$,</li>
              <li>A Beta distribution, $f(x)\propto(x-a)^{\alpha-1}(b-x)^{\beta-1}$</li>
            </ul>

            <p>For a rate variable $\lambda&gt;0$,</p>
            <ul>
              <li>May fix $f(\lambda)=c$ to indicate complete ignorance</li>
              <ul>
                <li>But this is probably not what you want!</li>
                <li>Places almost all probability on large values.</li>
              </ul>
              <li>$f(\lambda)=1/\lambda$ is a better choice (uniform in log-space)</li>

            </ul>

          </section>

          <section>
            <h3>Improper priors</h3>

            <blockquote class="alert" style="width:100%">Hold on, how can we choose a
              value of $c$ in $f(\lambda)=c$ so that $f(\lambda)$ is
              normalized on the domain of $\lambda$?<br>
            </blockquote>

            <img style="width:100%" data-src="uniform_improper.png">

            <blockquote style="width:100%">We can't! This $f(\lambda)$
            is not a true probability density.</blockquote>

            It turns out that this is usually okay, <b>provided the
              likelihood causes the posterior to be normalizable</b>.
          </section>

          <section>
            <h3>Improper priors (continued)</h3>
            However, for weak data sets improper priors can cause problems.
            It is important to remember that
            <ul>
              <li>One almost never knows absolutely nothing.</li>
              <li>Upper and lower bounds can almost always be placed.</li>
              <li>The log-normal prior can be considered a normalizable replacement for
              the $1/x$ prior.</li>
            </ul>

            <img style="width:100%" data-src="lognormal.png">

          </section>

          <section>
            <h3>Which prior is best?</h3>

            <blockquote class="alert" style="text-align:center;margin-top:150px;margin-bottom:50px">
              Only the person doing the analysis can answer this!
            </blockquote>

            Priors encapsulate expert knowledge (or its absence).
            This is your opportunity to contribute your hard-won
            expertise to the analysis.
          </section>
        </section>

        <section>
          <section class="center">
            <h2>Summarizing uncertainty</h2>
          </section>

          <section>
            <h3>Bayesian credible intervals</h3>

            For probability distributions/densities of a single
            variable, it is often useful to summarize the uncertainty
            in the value using an interval. For Bayesians this is the
            95% credible interval:

            <img style="width:100%" data-src="credible_interval.png">

            Here the interval is $[0.41, 0.91]$.

            <aside class="notes">
              What happens when distributions are bimodal?
              Watch significant figures.
              In general there is no strict frequency interpretation.
            </aside>
          </section>
        </section>

        <section>
          <section class="center">
            <h2>Inference in practice</h2>
          </section>

          <section>
            <h3>What's so difficult about this?</h3>

            <blockquote style="text-align:center">
              One word: integration.
            </blockquote>

            Bayes' theorem has a troublesome denominator:
            $$
            P(\theta_M|D,M)=\frac{P(D|\theta_M,M)P(\theta_M|M)}{P(D|M)}
            $$
            The quantity $P(D|M)$ is a normalizing constant, which is the
            result of integrating the numerator over all $\theta_M$:
            $$P(D|M)=\int P(D|\theta_M,M)P(\theta_M|M)d\theta_M$$

            <ul>
              <li>Unless you're <b>very</b> lucky, you can't do this
              integral with pen and paper.</li>
              <li>If $\theta_M$ has many dimensions, you can't even do
              this using a computer.</li>
            </ul>
          </section>

          <section>
            <h3>Monte Carlo methods</h3>

            <div style="text-align:center">
              <img style="width:80%" data-src="MonteCarlo.jpg">
            </div>
          </section>

          <section>
            <h3>Monte Carlo methods</h3>

            <div style="text-align:center">
              <img style="width:80%" data-src="casino.jpg">
            </div>
          </section>

          <section>
            <h3>Monte Carlo methods</h3>

            <p style="padding-top:50px">In our context, Monte Carlo
              methods are algorithms which produce random samples of
              values in order to characterize a probability
              distribution over those values.</p>

            <p style="padding-top:50px">Usually, the algorithms we
              deal with seek to produce an arbitrary number of
              independent samples of $\theta_M$ drawn from the
              posterior distribution $P(\theta_M|D,M)$.</p>
          </section>

          <section>
            <h3>Rejection sampling</h3>

            One of the simplest Monte Carlo methods for drawing from
            arbitrary distributions is the rejection sampler:

            <div style="width:800px;height:400px;position:relative;margin:0 auto">
              <img class="fragment current-visible" data-src="rejection_sampling12.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="rejection_sampling11.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="rejection_sampling10.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="rejection_sampling9.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="rejection_sampling8.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="rejection_sampling7.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="rejection_sampling6.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="rejection_sampling5.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="rejection_sampling4.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="rejection_sampling3.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="rejection_sampling2.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment" data-src="rejection_sampling1.svg"
                   style="position:absolute;top:0;left:0">
            </div>

            <p class="fragment">
            Reject <span style="color:red">red</span>
            samples, <span style="color:green">green</span> samples are
            drawn from target distribution.</p>
          </section>

          <section>
            <h3>The curse of dimensionality</h3>

            <img style="float:right;width:40%" data-src="curse.svg">

            <blockquote style="float:left;width:50%">
              In general, the fraction of an enclosing distribution
              occupied by a target distribution diminishes rapidly
              as the number of dimensions increases.
            </blockquote>

            <p style="clear:both;text-align:center;margin-top:100px">
              This means that for problems with large numbers of unknown parameters,
              rejection sampling will only ever produce rejects!</p>
          </section>

          <section>
            <h3>The Metropolis-Hastings algorithm</h3>

            This algorithm produces samples from a distribution $f(x)$ by generating a
            random walk over possible values of $x$.

            <div style="width:800px;height:400px;position:relative;margin:0 auto">
              <img class="fragment current-visible" data-src="MCMC1.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="MCMC2.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="MCMC3.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="MCMC4.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment current-visible" data-src="MCMC5.svg"
                   style="position:absolute;top:0;left:0">
              <img class="fragment" data-src="MCMC6.svg"
                   style="position:absolute;top:0;left:0">
            </div>

            <ol class="fragment">
              <li> walk explores mostly high probability areas</li>
              <li>algorithm <b>does not require normalized $f(x)$</b></li>
            </ol>
          </section>

          <section>
            <h3>Result of MCMC algorithm</h3>

            <br>
            <br>

            <div style="width:800px;height:400px;position:relative;margin:0 auto">
              <img class="current-visible" data-src="MCMC_trace.png"
                   style="position:absolute;top:0;left:0">
              <img class="fragment" data-src="MCMC_density.png"
                   style="position:absolute;top:0;left:0">
              </div>
          </section>

          <section>
            <h3>Convergence and Mixing</h3>

            <ul>
              <li>Adjacent MCMC samples for $x$ are <b>correlated</b>.</li>
              <li>In the limit of an infinite number of steps between a pair
              of samples, they will be independent draws.</li>
              <li>The first state of the MCMC chain is chosen
              arbitrarily - it is not a draw from the
              posterior.</li>
            </ul>

            <img style="width:100%" data-src="MCMC_burnin.svg">
          </section>

          <section>
            <h3>What determines convergence and mixing rates?</h3>

            <ul>
              <li>Convergence is affected by the starting state.</li>
              <li>Convergence and mixing are affected by</li>
              <ul>
                <li>Proposals: how big are the steps in the random
                walk? What direction are they in?</li>
                <li>The target density: multiple modes cause havoc!</li>
              </ul>
            </ul>

          </section>

          <section>
            <h3>Assessing Convergence</h3>

            The tried and true method for assessing convergence is to
            compare the results of distinct chains generated from
            independently selected initial conditions.

            <img style="float:right;width:45%" data-src="MCMC_convergence_testing.png">

            <div style="width:50%;margin-top:50px">
              <ul>
                <li>Once satisfied, chains can be combined.</li>
                <li>Can run at the same time on a cluster.</li>
                <li>Doesn't necessarily prove convergence!</li>
              </ul>
            </div>
          </section>

          <section>
            <h3>Assessing Mixing</h3>

            The key to assessing mixing is the autocorrelation function of the chain states:
            <img style="width:100%" data-src="MCMC_acf.png">

            The number of steps required for this function to decay to
            within the vicinity of 0 is the gap between effectively independent samples,
            $\tau$.
          </section>

          <section>
            <h3>Assessing Mixing (continued)</h3>

            If $N$ is the total number of MCMC samples, we then define
            $$N_{\text{eff}}=\frac{N}{\tau}$$
            to be the <b>effective sample size</b> (ESS).

            <p>The ESS is a rough <i>estimate</i> of the number of actual
            samples a chain has generated.</p>

            <blockquote>You should really only
            consider the order of magnitude of the ESS.</blockquote>
          </section>
        </section>

        <section>
          <h2>Further Reading</h2>

          <div class="figure" style="width:45%;float:left;text-align:center;margin-top:50px">
            <img style="height:400px" data-src="itiala_cover.png">
          </div> <div style="width:45%;float:right;text-align:center;margin-top:50px">
            <img style="height:400px" data-src="jaynes.jpg">
          </div>
        </section>
      </div>
    </div>

    <script src="../reveal.js/lib/js/head.min.js"></script>
    <script src="../reveal.js/js/reveal.js"></script>

    <script>
      // More info https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
      controls: false,
      progress: false,
      history: true,
      center: false,

      transition: 'convex',

      // More info https://github.com/hakimel/reveal.js#dependencies
      dependencies: [
      { src: '../reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: '../reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: '../reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: '../reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
      { src: '../reveal.js/plugin/zoom-js/zoom.js', async: true },
      { src: '../reveal.js/plugin/notes/notes.js', async: true },
      { src: '../reveal.js/plugin/math/math.js', async: true }
      ]
      });
    </script>
  </body>
</html>
